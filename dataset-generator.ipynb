{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb75caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "from matplotlib import patches\n",
    "import zipfile\n",
    "from pycocotools.coco import COCO\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random as rn\n",
    "from shutil import copyfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "235870f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.82s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.27s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load annotations for training data\n",
    "train_annot_path = 'data/annotations/person_keypoints_train2017.json'\n",
    "val_annot_path = 'data/annotations/person_keypoints_val2017.json'\n",
    "train_coco = COCO(train_annot_path) # load annotations for training set\n",
    "val_coco = COCO(val_annot_path) # load annotations for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f003a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load meta data on images: https://towardsdatascience.com/how-to-analyze-the-coco-dataset-for-pose-estimation-7296e2ffb12e\n",
    "def get_meta(coco):\n",
    "    ids = list(coco.imgs.keys())\n",
    "    for i, img_id in enumerate(ids):\n",
    "        img_meta = coco.imgs[img_id]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        # basic parameters of an image\n",
    "        img_file_name = img_meta['file_name']\n",
    "        w = img_meta['width']\n",
    "        h = img_meta['height']\n",
    "        # retrieve metadata for all persons in the current image\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        yield [img_id, img_file_name, w, h, anns]\n",
    "        \n",
    "def convert_to_df(coco):\n",
    "    images_data = []\n",
    "    persons_data = []\n",
    "    # iterate over all images\n",
    "    for img_id, img_fname, w, h, meta in get_meta(coco):\n",
    "        images_data.append({\n",
    "            'image_id': int(img_id),\n",
    "            'path': img_fname,\n",
    "            'width': int(w),\n",
    "            'height': int(h)\n",
    "        })\n",
    "        # iterate over all metadata\n",
    "        for m in meta:\n",
    "            persons_data.append({\n",
    "                'image_id': m['image_id'],\n",
    "                'is_crowd': m['iscrowd'],\n",
    "                'bbox': m['bbox'],\n",
    "                'area': m['area'],\n",
    "                'num_keypoints': m['num_keypoints'],\n",
    "                'keypoints': m['keypoints'],\n",
    "            })\n",
    "    # create dataframe with image paths\n",
    "    images_df = pd.DataFrame(images_data)\n",
    "    images_df.set_index('image_id', inplace=True)\n",
    "    # create dataframe with persons\n",
    "    persons_df = pd.DataFrame(persons_data)\n",
    "    persons_df.set_index('image_id', inplace=True)\n",
    "    return images_df, persons_df\n",
    "\n",
    "# Create train and validation dfs\n",
    "images_df, persons_df = convert_to_df(train_coco)\n",
    "train_coco_df = pd.merge(images_df, persons_df, right_index=True, left_index=True)\n",
    "\n",
    "images_df, persons_df = convert_to_df(val_coco)\n",
    "val_coco_df = pd.merge(images_df, persons_df, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1bbee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149813\n",
      "6352\n"
     ]
    }
   ],
   "source": [
    "# Drop all photos with no keypoints or where a group is just marked as crowd\n",
    "train_coco_df = train_coco_df[train_coco_df['is_crowd']==0]\n",
    "train_coco_df = train_coco_df[train_coco_df['num_keypoints']>0]\n",
    "# train_coco_df.drop_duplicates(subset=['path'], keep='first', inplace=True, ignore_index=False)\n",
    "\n",
    "val_coco_df = val_coco_df[val_coco_df['is_crowd']==0]\n",
    "val_coco_df = val_coco_df[val_coco_df['num_keypoints']>0]\n",
    "# val_coco_df.drop_duplicates(subset=['path'], keep='first', inplace=True, ignore_index=False)\n",
    "print(len(train_coco_df))\n",
    "print(len(val_coco_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7988214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing transform defined in the DeepPose paper\n",
    "# y is a 2 vec, b is a 4 vec of bcx, bcy, bw, bh\n",
    "def N(y, b):\n",
    "    return [ (y[0]-b[0]) * 1/b[2], (y[1]-b[1]) * 1/b[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "892de07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertKeyPoints(df, dimensions, source, index):\n",
    "    bbox = np.array(df.iloc[index][\"bbox\"]).astype(np.int64)\n",
    "    keypoints = df.iloc[index][\"keypoints\"]\n",
    "\n",
    "    bbox_tl_x = bbox[0]\n",
    "    bbox_tl_y = bbox[1]\n",
    "    w_original = bbox[2]\n",
    "    h_original = bbox[3]\n",
    "\n",
    "    bbox_rescale = [dimensions/2, dimensions/2, dimensions, dimensions]\n",
    "\n",
    "    # Move keypoints to new bbox locations accounting for crop, scale, and normalization\n",
    "    final_keypoints = []\n",
    "    for i in range(2, len(keypoints), 3):\n",
    "        x = (keypoints[i-2] - bbox_tl_x) * dimensions / w_original\n",
    "        y = (keypoints[i-1] - bbox_tl_y)* dimensions / h_original\n",
    "\n",
    "        x, y = N([x, y], bbox_rescale)\n",
    "        v = keypoints[i]\n",
    "\n",
    "        # If resizing put keypoint outside of image then remove it\n",
    "        if x < -0.5 or y < -0.5 or x > 0.5 or y > 0.5: v = 0\n",
    "\n",
    "        # Set keypoints to -1 if not visible\n",
    "        if v == 0:\n",
    "            x = -1\n",
    "            y = -1\n",
    "\n",
    "        # Add final keypoints to final_keypoints\n",
    "        final_keypoints.extend([x,y])\n",
    "\n",
    "    return final_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8535021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImg(df, dimensions, source, index):\n",
    "    img = image.imread(f'data/{source}2017/{df.iloc[index][\"path\"]}')\n",
    "    bbox = np.array(df.iloc[index][\"bbox\"]).astype(np.int64)\n",
    "    \n",
    "    # Account for potential gray images by adding channels\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        if (len(img.shape) == 2): img = np.expand_dims(img,-1)\n",
    "        img = cv2.merge([img,img,img])\n",
    "\n",
    "    # Crop image to bbox\n",
    "    img = img[bbox[1]:bbox[1]+bbox[3],bbox[0]:bbox[0]+bbox[2]]\n",
    "\n",
    "    # Scale image \n",
    "    img = cv2.resize(img, dsize=(dimensions, dimensions), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    img = img.astype('uint8') # enforce int \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "944e964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new final dataframes\n",
    "\n",
    "train_df = pd.DataFrame(columns = ['path', 'width', 'height', 'keypoints', 'num_keypoints'])\n",
    "val_df = pd.DataFrame(columns = ['path', 'width', 'height', 'keypoints', 'num_keypoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33c59a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0\n",
      "row 1000\n",
      "row 2000\n",
      "row 3000\n",
      "row 4000\n",
      "row 5000\n",
      "row 6000\n",
      "row 7000\n",
      "row 8000\n",
      "row 9000\n",
      "row 10000\n",
      "row 11000\n",
      "row 12000\n",
      "row 13000\n",
      "row 14000\n",
      "row 15000\n",
      "row 16000\n",
      "row 17000\n",
      "row 18000\n",
      "row 19000\n",
      "row 20000\n",
      "row 21000\n",
      "row 22000\n",
      "row 23000\n",
      "row 24000\n",
      "row 25000\n",
      "row 26000\n",
      "row 27000\n",
      "row 28000\n",
      "row 29000\n",
      "row 30000\n",
      "row 31000\n",
      "row 32000\n",
      "row 33000\n",
      "row 34000\n",
      "row 35000\n",
      "row 36000\n",
      "row 37000\n",
      "row 38000\n",
      "row 39000\n",
      "row 40000\n",
      "row 41000\n",
      "row 42000\n",
      "row 43000\n",
      "row 44000\n",
      "row 45000\n",
      "row 46000\n",
      "row 47000\n",
      "row 48000\n",
      "row 49000\n",
      "row 50000\n",
      "row 51000\n",
      "row 52000\n",
      "row 53000\n",
      "row 54000\n",
      "row 55000\n",
      "row 56000\n",
      "row 57000\n",
      "row 58000\n",
      "row 59000\n",
      "row 60000\n",
      "row 61000\n",
      "row 62000\n",
      "row 63000\n",
      "row 64000\n",
      "row 65000\n",
      "row 66000\n",
      "row 67000\n",
      "row 68000\n",
      "row 69000\n",
      "row 70000\n",
      "row 71000\n",
      "row 72000\n",
      "row 73000\n",
      "row 74000\n",
      "row 75000\n",
      "row 76000\n",
      "row 77000\n",
      "row 78000\n",
      "row 79000\n",
      "row 80000\n",
      "row 81000\n",
      "row 82000\n",
      "row 83000\n",
      "row 84000\n",
      "row 85000\n",
      "row 86000\n",
      "row 87000\n",
      "row 88000\n",
      "row 89000\n",
      "row 90000\n",
      "row 91000\n",
      "row 92000\n",
      "row 93000\n",
      "row 94000\n",
      "row 95000\n",
      "row 96000\n",
      "row 97000\n",
      "row 98000\n",
      "row 99000\n",
      "row 100000\n",
      "row 101000\n",
      "row 102000\n",
      "row 103000\n",
      "row 104000\n",
      "row 105000\n",
      "row 106000\n",
      "row 107000\n",
      "row 108000\n",
      "row 109000\n",
      "row 110000\n",
      "row 111000\n",
      "row 112000\n",
      "row 113000\n",
      "row 114000\n",
      "row 115000\n",
      "row 116000\n",
      "row 117000\n",
      "row 118000\n",
      "row 119000\n",
      "row 120000\n",
      "row 121000\n",
      "row 122000\n",
      "row 123000\n",
      "row 124000\n",
      "row 125000\n",
      "row 126000\n",
      "row 127000\n",
      "row 128000\n",
      "row 129000\n",
      "row 130000\n",
      "row 131000\n",
      "row 132000\n",
      "row 133000\n",
      "row 134000\n",
      "row 135000\n",
      "row 136000\n",
      "row 137000\n",
      "row 138000\n",
      "row 139000\n",
      "row 140000\n",
      "row 141000\n",
      "row 142000\n",
      "row 143000\n",
      "row 144000\n",
      "row 145000\n",
      "row 146000\n",
      "row 147000\n",
      "row 148000\n",
      "row 149000\n",
      "row 0\n",
      "row 1000\n",
      "row 2000\n",
      "row 3000\n",
      "row 4000\n",
      "row 5000\n",
      "row 6000\n",
      "row 0\n",
      "row 1000\n",
      "row 2000\n",
      "row 3000\n",
      "row 4000\n",
      "row 5000\n",
      "row 6000\n",
      "row 7000\n",
      "row 8000\n",
      "row 9000\n",
      "row 10000\n",
      "row 11000\n",
      "row 12000\n",
      "row 13000\n",
      "row 14000\n",
      "row 15000\n",
      "row 16000\n",
      "row 17000\n",
      "row 18000\n",
      "row 19000\n",
      "row 20000\n",
      "row 21000\n",
      "row 22000\n",
      "row 23000\n",
      "row 24000\n",
      "row 25000\n",
      "row 26000\n",
      "row 27000\n",
      "row 28000\n",
      "row 29000\n",
      "row 30000\n",
      "row 31000\n",
      "row 32000\n",
      "row 33000\n",
      "row 34000\n",
      "row 35000\n",
      "row 36000\n",
      "row 37000\n",
      "row 38000\n",
      "row 39000\n",
      "row 40000\n",
      "row 41000\n",
      "row 42000\n",
      "row 43000\n",
      "row 44000\n",
      "row 45000\n",
      "row 46000\n",
      "row 47000\n",
      "row 48000\n",
      "row 49000\n",
      "row 50000\n",
      "row 51000\n",
      "row 52000\n",
      "row 53000\n",
      "row 54000\n",
      "row 55000\n",
      "row 56000\n",
      "row 0\n",
      "row 1000\n",
      "row 2000\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data-2/train2017\n",
    "!mkdir -p data-2/val2017\n",
    "\n",
    "# Compute new keypoints for train_df\n",
    "for row in range(len(train_coco_df)):\n",
    "    df_row = train_coco_df.iloc[row]\n",
    "    kps = convertKeyPoints(train_coco_df, 224, 'train', row)\n",
    "    \n",
    "    train_df = train_df.append(\n",
    "        {\n",
    "            'path' : df_row['path'],\n",
    "            'width' : 224,\n",
    "            'height' : 224,\n",
    "            'keypoints' : kps,\n",
    "            'num_keypoints' : sum(1 for _ in filter(lambda score: score > -1, kps))\n",
    "        }\n",
    "        , ignore_index = True)\n",
    "    if row % 1000 == 0: print(f'row {row}')\n",
    "    \n",
    "# Compute new keypoints for val_df\n",
    "for row in range(len(val_coco_df)):\n",
    "    df_row = val_coco_df.iloc[row]\n",
    "    kps = convertKeyPoints(val_coco_df, 224, 'val', row)\n",
    "    \n",
    "    val_df = val_df.append(\n",
    "        {\n",
    "            'path' : df_row['path'],\n",
    "            'width' : 224,\n",
    "            'height' : 224,\n",
    "            'keypoints' : kps,\n",
    "            'num_keypoints' : sum(1 for _ in filter(lambda score: score > -1, kps))\n",
    "        }\n",
    "        , ignore_index = True)\n",
    "    if row % 1000 == 0: print(f'row {row}')\n",
    "    \n",
    "# Remove all duplicate files from dataframes\n",
    "train_coco_df.drop_duplicates(subset=['path'], keep='first', inplace=True, ignore_index=False)\n",
    "val_coco_df.drop_duplicates(subset=['path'], keep='first', inplace=True, ignore_index=False)\n",
    "\n",
    "# Create new cropped files in data-2\n",
    "for row in range(len(train_coco_df)):\n",
    "    df_row = train_coco_df.iloc[row]\n",
    "    img = convertImg(train_coco_df, 224, 'train', row)\n",
    "    cv2.imwrite(f'data-2/train2017/{train_coco_df.iloc[row][\"path\"]}', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    if row % 1000 == 0: print(f'row {row}')\n",
    "\n",
    "for row in range(len(val_coco_df)):\n",
    "    df_row = val_coco_df.iloc[row]\n",
    "    img = convertImg(val_coco_df, 224, 'val', row)\n",
    "    cv2.imwrite(f'data-2/val2017/{val_coco_df.iloc[row][\"path\"]}', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    if row % 1000 == 0: print(f'row {row}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfaafd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149813\n",
      "6352\n",
      "               path width height  \\\n",
      "0  000000000036.jpg   224    224   \n",
      "1  000000000049.jpg   224    224   \n",
      "2  000000000049.jpg   224    224   \n",
      "3  000000000077.jpg   224    224   \n",
      "4  000000000077.jpg   224    224   \n",
      "\n",
      "                                           keypoints num_keypoints  \n",
      "0  [-0.23225806451612901, -0.32365591397849464, -...            26  \n",
      "1  [0.2384615384615385, -0.2808219178082192, 0.26...            26  \n",
      "2  [0.21428571428571427, -0.3548387096774194, 0.2...            22  \n",
      "3  [-1, -1, -1, -1, -1, -1, -0.10194174757281552,...            28  \n",
      "4  [-1, -1, -1, -1, 0.148936170212766, -0.3350515...            28  \n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8e672b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pickle files and zip data\n",
    "# train_df.to_pickle('data-2/train_df.pkl')\n",
    "# val_df.to_pickle('data-2/val_df.pkl')\n",
    "\n",
    "!zip -r -j -q data.zip data-2/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3daac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
